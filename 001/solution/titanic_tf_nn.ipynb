{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/gimseng/99-ML-Learning-Projects/blob/master/001/solution/titanic_tf_nn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_url = 'https://raw.githubusercontent.com/gimseng/99-ML-Learning-Projects/'\n",
    "data_path = 'master/001/data/'\n",
    "train=pd.read_csv(project_url+data_path+'train.csv')\n",
    "test=pd.read_csv(project_url+data_path+'test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deleting the columns not required for determining the survival of a person\n",
    "\"\"\"\n",
    "\n",
    "del train['PassengerId']\n",
    "del train['Ticket']\n",
    "del train['Fare']\n",
    "del train['Cabin']\n",
    "del train['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Since there are ONLY 2 rows whose Embarked data is not known, \n",
    "therefore we can neglect those 2 rows as they will not make much of a difference\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Similarly, deleting the columns not required for determining the survival of a person for the data stored in test.csv\n",
    "\"\"\"\n",
    "\n",
    "del test['Ticket']\n",
    "del test['Fare']\n",
    "del test['Cabin']\n",
    "del test['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNum(str):\n",
    "    if str=='male':\n",
    "        return '1'\n",
    "    if str=='female':\n",
    "        return '2'\n",
    "train[\"Gender\"]=train[\"Sex\"].apply(getNum)\n",
    "#We have created a new column called \"Gender\" and \n",
    "#filling it with values 1 ,2 based on the values of sex column\n",
    "train.head()\n",
    "\n",
    "test[\"Gender\"]=test[\"Sex\"].apply(getNum)\n",
    "#We have created a new column called \"Gender\" and \n",
    "#filling it with values 1 ,2 based on the values of sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['Sex']\n",
    "del test['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived\n",
       "Pclass          \n",
       "3       0.242363\n",
       "2       0.472826\n",
       "1       0.629630"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Pclass','Survived']].groupby(['Pclass']).mean().sort_values(by='Survived',ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived\n",
       "Gender          \n",
       "1       0.188908\n",
       "2       0.742038"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Gender','Survived']].groupby(['Gender']).mean().sort_values(by='Survived',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survived\n",
       "SibSp          \n",
       "5      0.000000\n",
       "8      0.000000\n",
       "4      0.166667\n",
       "3      0.250000\n",
       "0      0.345395\n",
       "2      0.464286\n",
       "1      0.535885"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['SibSp','Survived']].groupby(['SibSp']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survived\n",
       "Parch          \n",
       "4      0.000000\n",
       "6      0.000000\n",
       "5      0.200000\n",
       "0      0.343658\n",
       "2      0.500000\n",
       "1      0.550847\n",
       "3      0.600000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Parch','Survived']].groupby(['Parch']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ce95511390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['Survived'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2ce975f4240>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_hist = sns.FacetGrid(train, col='Survived')\n",
    "age_hist.map(plt.hist, 'Age')\n",
    "age_hist.set_ylabels('Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2ce976a39e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468.8x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pclass_age_grid = sns.FacetGrid(train, col='Survived', row='Pclass', height=2.0, aspect=1.6)\n",
    "pclass_age_grid.map(plt.hist, 'Age', alpha=0.5, bins=20)\n",
    "pclass_age_grid.add_legend()\n",
    "pclass_age_grid.set_ylabels('Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.62617924528302"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding mean survived age\n",
    "mean_sur= train[train.Survived==1]['Age'].mean()\n",
    "mean_sur\n",
    "\n",
    "# Finding the mean age of \"Not Survived\" people\n",
    "mean_nsur=train[train['Survived']==0]['Age'].mean()\n",
    "mean_nsur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train, test]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train[\"Age\"].mean()\n",
    "    std = test[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    \n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    \n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train[\"Age\"].astype(int)\n",
    "    \n",
    "    \n",
    "train[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Age  SibSp  Parch Embarked Sex\n",
       "0         0       3   22      1      0        S   1\n",
       "1         1       1   38      1      0        C   2\n",
       "2         1       3   26      0      0        S   2\n",
       "3         1       1   35      1      0        S   2\n",
       "4         0       3   35      0      0        S   1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Renaming \"gender\" column\n",
    "train.rename(columns={'Gender':'Sex'}, inplace=True)\n",
    "\n",
    "test.rename(columns={'Gender':'Sex'}, inplace=True)\n",
    "\n",
    "#Removing the 2 rows having null value for Embarked column\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining 'Parch' & 'SibSp' as 'Realtives'\n",
    "train['Family_Members']=train['Parch']+train['SibSp'] + 1\n",
    "test['Family_Members']=test['Parch']+test['SibSp'] + 1\n",
    "\n",
    "del train['SibSp']\n",
    "del train['Parch']\n",
    "\n",
    "del test['SibSp']\n",
    "del test['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    159\n",
       "2    158\n",
       "3    151\n",
       "1    150\n",
       "5    107\n",
       "6    100\n",
       "0     64\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[train,test]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Age'] <= 10, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 10) & (dataset['Age'] <= 20), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 20) & (dataset['Age'] <= 25), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 25) & (dataset['Age'] <= 30), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 30) & (dataset['Age'] <= 37), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 37) & (dataset['Age'] <= 45), 'Age'] = 5\n",
    "    dataset.loc[ dataset['Age'] > 45 , 'Age'] = 6\n",
    "\n",
    "train['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Family_Members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Age  Embarked Sex  Family_Members\n",
       "0         0       3    2         1   1               2\n",
       "1         1       1    5         0   2               2\n",
       "2         1       3    3         1   2               1\n",
       "3         1       1    4         1   2               2\n",
       "4         0       3    4         1   1               1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[train,test]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked']=dataset['Embarked'].map({'C': 0, 'S': 1, 'Q': 2}).astype(int)\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ce976ec978>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train= train.drop(['Survived'], axis =1)\n",
    "y_train= train['Survived']\n",
    "\n",
    "X_test=test.drop('PassengerId', axis=1).copy()\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL-NETWORKS (KERAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Family_Members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Age  Embarked Sex  Family_Members\n",
       "0       3    2         2   1               1\n",
       "1       3    5         1   2               2\n",
       "2       2    3         2   1               1\n",
       "3       3    4         1   1               1\n",
       "4       3    4         1   2               3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(test)\n",
    "X_test=test.drop('PassengerId', axis=1).copy()\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras import backend as K\n",
    "X_train = K.cast_to_floatx(X_train)\n",
    "y_train = K.cast_to_floatx(y_train)\n",
    "\n",
    "X_test = K.cast_to_floatx(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer with 5 neurons\n",
    "model.add(Dense(10, activation = 'relu', input_dim = 5))\n",
    "#Hidden layer\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'relu'))\n",
    "\n",
    "#output layer with 1 output neuron which will predict 1 or 0\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.7171 - accuracy: 0.6104 - val_loss: 0.6940 - val_accuracy: 0.6461\n",
      "Epoch 2/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.6104 - val_loss: 0.6592 - val_accuracy: 0.6461\n",
      "Epoch 3/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.6104 - val_loss: 0.6298 - val_accuracy: 0.6461\n",
      "Epoch 4/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.6104 - val_loss: 0.5877 - val_accuracy: 0.6461\n",
      "Epoch 5/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.6104 - val_loss: 0.5547 - val_accuracy: 0.6461\n",
      "Epoch 6/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.6104 - val_loss: 0.5325 - val_accuracy: 0.6461\n",
      "Epoch 7/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5607 - accuracy: 0.6104 - val_loss: 0.5192 - val_accuracy: 0.6461\n",
      "Epoch 8/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5518 - accuracy: 0.6104 - val_loss: 0.5118 - val_accuracy: 0.6461\n",
      "Epoch 9/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.6526 - val_loss: 0.5039 - val_accuracy: 0.8146\n",
      "Epoch 10/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7750 - val_loss: 0.4994 - val_accuracy: 0.8090\n",
      "Epoch 11/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7876 - val_loss: 0.4949 - val_accuracy: 0.8090\n",
      "Epoch 12/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7876 - val_loss: 0.4928 - val_accuracy: 0.8090\n",
      "Epoch 13/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7876 - val_loss: 0.4902 - val_accuracy: 0.8090\n",
      "Epoch 14/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7862 - val_loss: 0.4868 - val_accuracy: 0.8090\n",
      "Epoch 15/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7848 - val_loss: 0.4843 - val_accuracy: 0.8090\n",
      "Epoch 16/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7904 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
      "Epoch 17/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.7890 - val_loss: 0.4783 - val_accuracy: 0.8090\n",
      "Epoch 18/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7890 - val_loss: 0.4767 - val_accuracy: 0.8034\n",
      "Epoch 19/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7890 - val_loss: 0.4748 - val_accuracy: 0.8034\n",
      "Epoch 20/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.7904 - val_loss: 0.4721 - val_accuracy: 0.8090\n",
      "Epoch 21/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7904 - val_loss: 0.4700 - val_accuracy: 0.8090\n",
      "Epoch 22/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7890 - val_loss: 0.4674 - val_accuracy: 0.8090\n",
      "Epoch 23/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7918 - val_loss: 0.4668 - val_accuracy: 0.8146\n",
      "Epoch 24/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.7862 - val_loss: 0.4642 - val_accuracy: 0.8146\n",
      "Epoch 25/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7876 - val_loss: 0.4624 - val_accuracy: 0.8146\n",
      "Epoch 26/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7904 - val_loss: 0.4598 - val_accuracy: 0.8146\n",
      "Epoch 27/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7932 - val_loss: 0.4587 - val_accuracy: 0.8202\n",
      "Epoch 28/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7932 - val_loss: 0.4572 - val_accuracy: 0.8090\n",
      "Epoch 29/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7961 - val_loss: 0.4535 - val_accuracy: 0.8202\n",
      "Epoch 30/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7932 - val_loss: 0.4526 - val_accuracy: 0.8202\n",
      "Epoch 31/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7947 - val_loss: 0.4532 - val_accuracy: 0.8090\n",
      "Epoch 32/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7975 - val_loss: 0.4494 - val_accuracy: 0.8146\n",
      "Epoch 33/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.7904 - val_loss: 0.4472 - val_accuracy: 0.8146\n",
      "Epoch 34/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.7975 - val_loss: 0.4456 - val_accuracy: 0.8202\n",
      "Epoch 35/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7961 - val_loss: 0.4434 - val_accuracy: 0.8258\n",
      "Epoch 36/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7961 - val_loss: 0.4414 - val_accuracy: 0.8258\n",
      "Epoch 37/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.7961 - val_loss: 0.4408 - val_accuracy: 0.8258\n",
      "Epoch 38/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4910 - accuracy: 0.7975 - val_loss: 0.4387 - val_accuracy: 0.8258\n",
      "Epoch 39/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7961 - val_loss: 0.4374 - val_accuracy: 0.8315\n",
      "Epoch 40/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.8017 - val_loss: 0.4342 - val_accuracy: 0.8315\n",
      "Epoch 41/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7989 - val_loss: 0.4332 - val_accuracy: 0.8258\n",
      "Epoch 42/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7989 - val_loss: 0.4312 - val_accuracy: 0.8258\n",
      "Epoch 43/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.8017 - val_loss: 0.4323 - val_accuracy: 0.8483\n",
      "Epoch 44/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.8031 - val_loss: 0.4269 - val_accuracy: 0.8315\n",
      "Epoch 45/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.8031 - val_loss: 0.4257 - val_accuracy: 0.8258\n",
      "Epoch 46/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.8059 - val_loss: 0.4248 - val_accuracy: 0.8371\n",
      "Epoch 47/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.8073 - val_loss: 0.4227 - val_accuracy: 0.8371\n",
      "Epoch 48/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.8101 - val_loss: 0.4223 - val_accuracy: 0.8371\n",
      "Epoch 49/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.8073 - val_loss: 0.4217 - val_accuracy: 0.8483\n",
      "Epoch 50/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.8115 - val_loss: 0.4192 - val_accuracy: 0.8371\n",
      "Epoch 51/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.8129 - val_loss: 0.4179 - val_accuracy: 0.8258\n",
      "Epoch 52/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.8101 - val_loss: 0.4163 - val_accuracy: 0.8371\n",
      "Epoch 53/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.8115 - val_loss: 0.4153 - val_accuracy: 0.8371\n",
      "Epoch 54/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.8101 - val_loss: 0.4132 - val_accuracy: 0.8371\n",
      "Epoch 55/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.8143 - val_loss: 0.4134 - val_accuracy: 0.8427\n",
      "Epoch 56/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.8129 - val_loss: 0.4098 - val_accuracy: 0.8371\n",
      "Epoch 57/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.8087 - val_loss: 0.4093 - val_accuracy: 0.8483\n",
      "Epoch 58/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.8115 - val_loss: 0.4077 - val_accuracy: 0.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8158 - val_loss: 0.4098 - val_accuracy: 0.8427\n",
      "Epoch 60/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.8087 - val_loss: 0.4055 - val_accuracy: 0.8427\n",
      "Epoch 61/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.8087 - val_loss: 0.4060 - val_accuracy: 0.8371\n",
      "Epoch 62/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.8115 - val_loss: 0.4023 - val_accuracy: 0.8371\n",
      "Epoch 63/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.8101 - val_loss: 0.4044 - val_accuracy: 0.8483\n",
      "Epoch 64/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.8158 - val_loss: 0.4034 - val_accuracy: 0.8427\n",
      "Epoch 65/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.8115 - val_loss: 0.4001 - val_accuracy: 0.8315\n",
      "Epoch 66/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8129 - val_loss: 0.4002 - val_accuracy: 0.8371\n",
      "Epoch 67/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.8186 - val_loss: 0.4002 - val_accuracy: 0.8371\n",
      "Epoch 68/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.8101 - val_loss: 0.3968 - val_accuracy: 0.8427\n",
      "Epoch 69/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.8115 - val_loss: 0.3998 - val_accuracy: 0.8427\n",
      "Epoch 70/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8186 - val_loss: 0.3985 - val_accuracy: 0.8371\n",
      "Epoch 71/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.8200 - val_loss: 0.3968 - val_accuracy: 0.8371\n",
      "Epoch 72/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8115 - val_loss: 0.3949 - val_accuracy: 0.8371\n",
      "Epoch 73/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.8143 - val_loss: 0.3940 - val_accuracy: 0.8371\n",
      "Epoch 74/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.8186 - val_loss: 0.3928 - val_accuracy: 0.8371\n",
      "Epoch 75/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.8158 - val_loss: 0.3926 - val_accuracy: 0.8315\n",
      "Epoch 76/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.8143 - val_loss: 0.3939 - val_accuracy: 0.8315\n",
      "Epoch 77/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.8087 - val_loss: 0.3921 - val_accuracy: 0.8315\n",
      "Epoch 78/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.8200 - val_loss: 0.3912 - val_accuracy: 0.8315\n",
      "Epoch 79/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.8143 - val_loss: 0.3883 - val_accuracy: 0.8315\n",
      "Epoch 80/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8186 - val_loss: 0.3891 - val_accuracy: 0.8483\n",
      "Epoch 81/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.8200 - val_loss: 0.3873 - val_accuracy: 0.8315\n",
      "Epoch 82/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8186 - val_loss: 0.3851 - val_accuracy: 0.8315\n",
      "Epoch 83/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8200 - val_loss: 0.3876 - val_accuracy: 0.8371\n",
      "Epoch 84/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.8200 - val_loss: 0.3842 - val_accuracy: 0.8315\n",
      "Epoch 85/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8158 - val_loss: 0.3831 - val_accuracy: 0.8427\n",
      "Epoch 86/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8186 - val_loss: 0.3817 - val_accuracy: 0.8315\n",
      "Epoch 87/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8200 - val_loss: 0.3814 - val_accuracy: 0.8371\n",
      "Epoch 88/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.8214 - val_loss: 0.3826 - val_accuracy: 0.8483\n",
      "Epoch 89/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8200 - val_loss: 0.3809 - val_accuracy: 0.8371\n",
      "Epoch 90/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8186 - val_loss: 0.3808 - val_accuracy: 0.8371\n",
      "Epoch 91/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8200 - val_loss: 0.3774 - val_accuracy: 0.8315\n",
      "Epoch 92/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8186 - val_loss: 0.3772 - val_accuracy: 0.8483\n",
      "Epoch 93/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8228 - val_loss: 0.3779 - val_accuracy: 0.8371\n",
      "Epoch 94/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.8200 - val_loss: 0.3749 - val_accuracy: 0.8371\n",
      "Epoch 95/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8228 - val_loss: 0.3795 - val_accuracy: 0.8427\n",
      "Epoch 96/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8200 - val_loss: 0.3773 - val_accuracy: 0.8427\n",
      "Epoch 97/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.8242 - val_loss: 0.3753 - val_accuracy: 0.8427\n",
      "Epoch 98/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8200 - val_loss: 0.3744 - val_accuracy: 0.8483\n",
      "Epoch 99/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8214 - val_loss: 0.3746 - val_accuracy: 0.8427\n",
      "Epoch 100/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8256 - val_loss: 0.3724 - val_accuracy: 0.8596\n",
      "Epoch 101/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.8186 - val_loss: 0.3699 - val_accuracy: 0.8483\n",
      "Epoch 102/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8228 - val_loss: 0.3703 - val_accuracy: 0.8483\n",
      "Epoch 103/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.8214 - val_loss: 0.3699 - val_accuracy: 0.8483\n",
      "Epoch 104/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8284 - val_loss: 0.3678 - val_accuracy: 0.8371\n",
      "Epoch 105/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8214 - val_loss: 0.3706 - val_accuracy: 0.8483\n",
      "Epoch 106/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8270 - val_loss: 0.3682 - val_accuracy: 0.8427\n",
      "Epoch 107/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8312 - val_loss: 0.3664 - val_accuracy: 0.8427\n",
      "Epoch 108/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8298 - val_loss: 0.3687 - val_accuracy: 0.8539\n",
      "Epoch 109/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8284 - val_loss: 0.3688 - val_accuracy: 0.8596\n",
      "Epoch 110/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8256 - val_loss: 0.3665 - val_accuracy: 0.8539\n",
      "Epoch 111/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.8214 - val_loss: 0.3634 - val_accuracy: 0.8539\n",
      "Epoch 112/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8270 - val_loss: 0.3690 - val_accuracy: 0.8539\n",
      "Epoch 113/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8172 - val_loss: 0.3649 - val_accuracy: 0.8483\n",
      "Epoch 114/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8242 - val_loss: 0.3678 - val_accuracy: 0.8652\n",
      "Epoch 115/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8270 - val_loss: 0.3680 - val_accuracy: 0.8596\n",
      "Epoch 116/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8284 - val_loss: 0.3670 - val_accuracy: 0.8652\n",
      "Epoch 117/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8228 - val_loss: 0.3665 - val_accuracy: 0.8483\n",
      "Epoch 118/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8270 - val_loss: 0.3655 - val_accuracy: 0.8539\n",
      "Epoch 119/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.8172 - val_loss: 0.3631 - val_accuracy: 0.8539\n",
      "Epoch 120/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8214 - val_loss: 0.3646 - val_accuracy: 0.8539\n",
      "Epoch 121/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.8256 - val_loss: 0.3640 - val_accuracy: 0.8539\n",
      "Epoch 122/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8200 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
      "Epoch 123/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8298 - val_loss: 0.3647 - val_accuracy: 0.8483\n",
      "Epoch 124/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8298 - val_loss: 0.3670 - val_accuracy: 0.8652\n",
      "Epoch 125/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8200 - val_loss: 0.3651 - val_accuracy: 0.8483\n",
      "Epoch 126/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8200 - val_loss: 0.3619 - val_accuracy: 0.8427\n",
      "Epoch 127/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8256 - val_loss: 0.3649 - val_accuracy: 0.8539\n",
      "Epoch 128/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8242 - val_loss: 0.3624 - val_accuracy: 0.8483\n",
      "Epoch 129/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8312 - val_loss: 0.3613 - val_accuracy: 0.8427\n",
      "Epoch 130/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8256 - val_loss: 0.3628 - val_accuracy: 0.8483\n",
      "Epoch 131/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.3623 - val_accuracy: 0.8483\n",
      "Epoch 132/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.8256 - val_loss: 0.3649 - val_accuracy: 0.8427\n",
      "Epoch 133/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.8256 - val_loss: 0.3614 - val_accuracy: 0.8483\n",
      "Epoch 134/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8256 - val_loss: 0.3658 - val_accuracy: 0.8596\n",
      "Epoch 135/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8284 - val_loss: 0.3643 - val_accuracy: 0.8483\n",
      "Epoch 136/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.8270 - val_loss: 0.3617 - val_accuracy: 0.8539\n",
      "Epoch 137/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8298 - val_loss: 0.3647 - val_accuracy: 0.8539\n",
      "Epoch 138/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.8242 - val_loss: 0.3640 - val_accuracy: 0.8652\n",
      "Epoch 139/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8242 - val_loss: 0.3611 - val_accuracy: 0.8427\n",
      "Epoch 140/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8312 - val_loss: 0.3627 - val_accuracy: 0.8539\n",
      "Epoch 141/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8242 - val_loss: 0.3627 - val_accuracy: 0.8539\n",
      "Epoch 142/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8284 - val_loss: 0.3645 - val_accuracy: 0.8427\n",
      "Epoch 143/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8298 - val_loss: 0.3633 - val_accuracy: 0.8427\n",
      "Epoch 144/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8284 - val_loss: 0.3661 - val_accuracy: 0.8483\n",
      "Epoch 145/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8256 - val_loss: 0.3656 - val_accuracy: 0.8483\n",
      "Epoch 146/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8298 - val_loss: 0.3652 - val_accuracy: 0.8483\n",
      "Epoch 147/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8270 - val_loss: 0.3669 - val_accuracy: 0.8483\n",
      "Epoch 148/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8270 - val_loss: 0.3625 - val_accuracy: 0.8371\n",
      "Epoch 149/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8340 - val_loss: 0.3658 - val_accuracy: 0.8483\n",
      "Epoch 150/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8312 - val_loss: 0.3640 - val_accuracy: 0.8539\n",
      "Epoch 151/800\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.4167 - accuracy: 0.8340 - val_loss: 0.3669 - val_accuracy: 0.8483\n",
      "Epoch 152/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8326 - val_loss: 0.3630 - val_accuracy: 0.8539\n",
      "Epoch 153/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8340 - val_loss: 0.3616 - val_accuracy: 0.8427\n",
      "Epoch 154/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8284 - val_loss: 0.3608 - val_accuracy: 0.8539\n",
      "Epoch 155/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8284 - val_loss: 0.3624 - val_accuracy: 0.8427\n",
      "Epoch 156/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8284 - val_loss: 0.3686 - val_accuracy: 0.8483\n",
      "Epoch 157/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8298 - val_loss: 0.3673 - val_accuracy: 0.8427\n",
      "Epoch 158/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8298 - val_loss: 0.3626 - val_accuracy: 0.8427\n",
      "Epoch 159/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8340 - val_loss: 0.3641 - val_accuracy: 0.8483\n",
      "Epoch 160/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8242 - val_loss: 0.3663 - val_accuracy: 0.8596\n",
      "Epoch 161/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8284 - val_loss: 0.3600 - val_accuracy: 0.8596\n",
      "Epoch 162/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8284 - val_loss: 0.3643 - val_accuracy: 0.8483\n",
      "Epoch 163/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8340 - val_loss: 0.3600 - val_accuracy: 0.8427\n",
      "Epoch 164/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8256 - val_loss: 0.3603 - val_accuracy: 0.8483\n",
      "Epoch 165/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8256 - val_loss: 0.3616 - val_accuracy: 0.8539\n",
      "Epoch 166/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8354 - val_loss: 0.3606 - val_accuracy: 0.8539\n",
      "Epoch 167/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8284 - val_loss: 0.3566 - val_accuracy: 0.8483\n",
      "Epoch 168/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8326 - val_loss: 0.3571 - val_accuracy: 0.8427\n",
      "Epoch 169/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8354 - val_loss: 0.3571 - val_accuracy: 0.8539\n",
      "Epoch 170/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8326 - val_loss: 0.3552 - val_accuracy: 0.8427\n",
      "Epoch 171/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8326 - val_loss: 0.3571 - val_accuracy: 0.8596\n",
      "Epoch 172/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8368 - val_loss: 0.3569 - val_accuracy: 0.8483\n",
      "Epoch 173/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8354 - val_loss: 0.3580 - val_accuracy: 0.8483\n",
      "Epoch 174/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8368 - val_loss: 0.3550 - val_accuracy: 0.8596\n",
      "Epoch 175/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8326 - val_loss: 0.3539 - val_accuracy: 0.8539\n",
      "Epoch 176/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8326 - val_loss: 0.3560 - val_accuracy: 0.8539\n",
      "Epoch 177/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8354 - val_loss: 0.3557 - val_accuracy: 0.8539\n",
      "Epoch 178/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8340 - val_loss: 0.3523 - val_accuracy: 0.8596\n",
      "Epoch 179/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8340 - val_loss: 0.3530 - val_accuracy: 0.8596\n",
      "Epoch 180/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8383 - val_loss: 0.3557 - val_accuracy: 0.8596\n",
      "Epoch 181/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8383 - val_loss: 0.3563 - val_accuracy: 0.8483\n",
      "Epoch 182/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8368 - val_loss: 0.3548 - val_accuracy: 0.8539\n",
      "Epoch 183/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8411 - val_loss: 0.3544 - val_accuracy: 0.8596\n",
      "Epoch 184/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8397 - val_loss: 0.3572 - val_accuracy: 0.8483\n",
      "Epoch 185/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8312 - val_loss: 0.3512 - val_accuracy: 0.8539\n",
      "Epoch 186/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8411 - val_loss: 0.3543 - val_accuracy: 0.8539\n",
      "Epoch 187/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8368 - val_loss: 0.3528 - val_accuracy: 0.8596\n",
      "Epoch 188/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8298 - val_loss: 0.3519 - val_accuracy: 0.8596\n",
      "Epoch 189/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8298 - val_loss: 0.3508 - val_accuracy: 0.8596\n",
      "Epoch 190/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8354 - val_loss: 0.3533 - val_accuracy: 0.8596\n",
      "Epoch 191/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8340 - val_loss: 0.3522 - val_accuracy: 0.8596\n",
      "Epoch 192/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8326 - val_loss: 0.3547 - val_accuracy: 0.8539\n",
      "Epoch 193/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8383 - val_loss: 0.3523 - val_accuracy: 0.8596\n",
      "Epoch 194/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8340 - val_loss: 0.3529 - val_accuracy: 0.8596\n",
      "Epoch 195/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8383 - val_loss: 0.3522 - val_accuracy: 0.8596\n",
      "Epoch 196/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8383 - val_loss: 0.3539 - val_accuracy: 0.8539\n",
      "Epoch 197/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8411 - val_loss: 0.3515 - val_accuracy: 0.8596\n",
      "Epoch 198/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8340 - val_loss: 0.3517 - val_accuracy: 0.8596\n",
      "Epoch 199/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8354 - val_loss: 0.3537 - val_accuracy: 0.8539\n",
      "Epoch 200/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8397 - val_loss: 0.3557 - val_accuracy: 0.8596\n",
      "Epoch 201/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8425 - val_loss: 0.3520 - val_accuracy: 0.8652\n",
      "Epoch 202/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8354 - val_loss: 0.3518 - val_accuracy: 0.8596\n",
      "Epoch 203/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8340 - val_loss: 0.3533 - val_accuracy: 0.8539\n",
      "Epoch 204/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8326 - val_loss: 0.3527 - val_accuracy: 0.8596\n",
      "Epoch 205/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8467 - val_loss: 0.3523 - val_accuracy: 0.8596\n",
      "Epoch 206/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8326 - val_loss: 0.3517 - val_accuracy: 0.8652\n",
      "Epoch 207/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8383 - val_loss: 0.3519 - val_accuracy: 0.8596\n",
      "Epoch 208/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8368 - val_loss: 0.3508 - val_accuracy: 0.8596\n",
      "Epoch 209/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8453 - val_loss: 0.3497 - val_accuracy: 0.8596\n",
      "Epoch 210/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8383 - val_loss: 0.3515 - val_accuracy: 0.8539\n",
      "Epoch 211/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8298 - val_loss: 0.3513 - val_accuracy: 0.8596\n",
      "Epoch 212/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8298 - val_loss: 0.3499 - val_accuracy: 0.8596\n",
      "Epoch 213/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8340 - val_loss: 0.3504 - val_accuracy: 0.8652\n",
      "Epoch 214/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8397 - val_loss: 0.3515 - val_accuracy: 0.8708\n",
      "Epoch 215/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8425 - val_loss: 0.3515 - val_accuracy: 0.8539\n",
      "Epoch 216/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8397 - val_loss: 0.3520 - val_accuracy: 0.8652\n",
      "Epoch 217/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8411 - val_loss: 0.3526 - val_accuracy: 0.8596\n",
      "Epoch 218/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8354 - val_loss: 0.3510 - val_accuracy: 0.8596\n",
      "Epoch 219/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8354 - val_loss: 0.3515 - val_accuracy: 0.8596\n",
      "Epoch 220/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8326 - val_loss: 0.3560 - val_accuracy: 0.8539\n",
      "Epoch 221/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8383 - val_loss: 0.3557 - val_accuracy: 0.8596\n",
      "Epoch 222/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8340 - val_loss: 0.3557 - val_accuracy: 0.8596\n",
      "Epoch 223/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8397 - val_loss: 0.3541 - val_accuracy: 0.8708\n",
      "Epoch 224/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.3539 - val_accuracy: 0.8652\n",
      "Epoch 225/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8425 - val_loss: 0.3536 - val_accuracy: 0.8596\n",
      "Epoch 226/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8312 - val_loss: 0.3507 - val_accuracy: 0.8708\n",
      "Epoch 227/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8368 - val_loss: 0.3535 - val_accuracy: 0.8596\n",
      "Epoch 228/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8383 - val_loss: 0.3592 - val_accuracy: 0.8596\n",
      "Epoch 229/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8326 - val_loss: 0.3526 - val_accuracy: 0.8652\n",
      "Epoch 230/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8397 - val_loss: 0.3553 - val_accuracy: 0.8596\n",
      "Epoch 231/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8425 - val_loss: 0.3572 - val_accuracy: 0.8539\n",
      "Epoch 232/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8284 - val_loss: 0.3527 - val_accuracy: 0.8652\n",
      "Epoch 233/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8383 - val_loss: 0.3517 - val_accuracy: 0.8596\n",
      "Epoch 234/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8453 - val_loss: 0.3533 - val_accuracy: 0.8652\n",
      "Epoch 235/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8397 - val_loss: 0.3507 - val_accuracy: 0.8596\n",
      "Epoch 236/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8425 - val_loss: 0.3526 - val_accuracy: 0.8596\n",
      "Epoch 237/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8354 - val_loss: 0.3531 - val_accuracy: 0.8596\n",
      "Epoch 238/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8340 - val_loss: 0.3524 - val_accuracy: 0.8652\n",
      "Epoch 239/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8411 - val_loss: 0.3543 - val_accuracy: 0.8596\n",
      "Epoch 240/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8326 - val_loss: 0.3539 - val_accuracy: 0.8652\n",
      "Epoch 241/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8354 - val_loss: 0.3528 - val_accuracy: 0.8596\n",
      "Epoch 242/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8383 - val_loss: 0.3533 - val_accuracy: 0.8596\n",
      "Epoch 243/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3837 - accuracy: 0.8368 - val_loss: 0.3532 - val_accuracy: 0.8539\n",
      "Epoch 244/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8397 - val_loss: 0.3564 - val_accuracy: 0.8596\n",
      "Epoch 245/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8397 - val_loss: 0.3574 - val_accuracy: 0.8483\n",
      "Epoch 246/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8383 - val_loss: 0.3550 - val_accuracy: 0.8652\n",
      "Epoch 247/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8397 - val_loss: 0.3524 - val_accuracy: 0.8708\n",
      "Epoch 248/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8397 - val_loss: 0.3561 - val_accuracy: 0.8539\n",
      "Epoch 249/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8439 - val_loss: 0.3522 - val_accuracy: 0.8652\n",
      "Epoch 250/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8397 - val_loss: 0.3529 - val_accuracy: 0.8652\n",
      "Epoch 251/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8312 - val_loss: 0.3523 - val_accuracy: 0.8596\n",
      "Epoch 252/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8368 - val_loss: 0.3508 - val_accuracy: 0.8652\n",
      "Epoch 253/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8326 - val_loss: 0.3543 - val_accuracy: 0.8708\n",
      "Epoch 254/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8411 - val_loss: 0.3542 - val_accuracy: 0.8596\n",
      "Epoch 255/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8383 - val_loss: 0.3521 - val_accuracy: 0.8708\n",
      "Epoch 256/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8383 - val_loss: 0.3532 - val_accuracy: 0.8708\n",
      "Epoch 257/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8397 - val_loss: 0.3538 - val_accuracy: 0.8708\n",
      "Epoch 258/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8397 - val_loss: 0.3524 - val_accuracy: 0.8708\n",
      "Epoch 259/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8439 - val_loss: 0.3535 - val_accuracy: 0.8596\n",
      "Epoch 260/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8340 - val_loss: 0.3549 - val_accuracy: 0.8708\n",
      "Epoch 261/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8298 - val_loss: 0.3544 - val_accuracy: 0.8596\n",
      "Epoch 262/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8411 - val_loss: 0.3523 - val_accuracy: 0.8596\n",
      "Epoch 263/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8368 - val_loss: 0.3521 - val_accuracy: 0.8652\n",
      "Epoch 264/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8425 - val_loss: 0.3571 - val_accuracy: 0.8539\n",
      "Epoch 265/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8340 - val_loss: 0.3511 - val_accuracy: 0.8708\n",
      "Epoch 266/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8411 - val_loss: 0.3571 - val_accuracy: 0.8596\n",
      "Epoch 267/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.3566 - val_accuracy: 0.8483\n",
      "Epoch 268/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8368 - val_loss: 0.3543 - val_accuracy: 0.8708\n",
      "Epoch 269/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8425 - val_loss: 0.3556 - val_accuracy: 0.8652\n",
      "Epoch 270/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8354 - val_loss: 0.3543 - val_accuracy: 0.8652\n",
      "Epoch 271/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8425 - val_loss: 0.3550 - val_accuracy: 0.8539\n",
      "Epoch 272/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8383 - val_loss: 0.3534 - val_accuracy: 0.8596\n",
      "Epoch 273/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8368 - val_loss: 0.3570 - val_accuracy: 0.8708\n",
      "Epoch 274/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8411 - val_loss: 0.3554 - val_accuracy: 0.8539\n",
      "Epoch 275/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8411 - val_loss: 0.3554 - val_accuracy: 0.8652\n",
      "Epoch 276/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8425 - val_loss: 0.3563 - val_accuracy: 0.8539\n",
      "Epoch 277/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8354 - val_loss: 0.3579 - val_accuracy: 0.8652\n",
      "Epoch 278/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8383 - val_loss: 0.3635 - val_accuracy: 0.8539\n",
      "Epoch 279/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8354 - val_loss: 0.3552 - val_accuracy: 0.8652\n",
      "Epoch 280/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8439 - val_loss: 0.3572 - val_accuracy: 0.8652\n",
      "Epoch 281/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8425 - val_loss: 0.3537 - val_accuracy: 0.8539\n",
      "Epoch 282/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8467 - val_loss: 0.3538 - val_accuracy: 0.8708\n",
      "Epoch 283/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8467 - val_loss: 0.3542 - val_accuracy: 0.8596\n",
      "Epoch 284/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8383 - val_loss: 0.3553 - val_accuracy: 0.8539\n",
      "Epoch 285/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.3558 - val_accuracy: 0.8652\n",
      "Epoch 286/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8397 - val_loss: 0.3584 - val_accuracy: 0.8539\n",
      "Epoch 287/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8383 - val_loss: 0.3543 - val_accuracy: 0.8652\n",
      "Epoch 288/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8383 - val_loss: 0.3541 - val_accuracy: 0.8596\n",
      "Epoch 289/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8397 - val_loss: 0.3557 - val_accuracy: 0.8708\n",
      "Epoch 290/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8425 - val_loss: 0.3596 - val_accuracy: 0.8652\n",
      "Epoch 291/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8439 - val_loss: 0.3546 - val_accuracy: 0.8539\n",
      "Epoch 292/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8397 - val_loss: 0.3541 - val_accuracy: 0.8652\n",
      "Epoch 293/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8425 - val_loss: 0.3580 - val_accuracy: 0.8483\n",
      "Epoch 294/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8383 - val_loss: 0.3580 - val_accuracy: 0.8596\n",
      "Epoch 295/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8425 - val_loss: 0.3561 - val_accuracy: 0.8708\n",
      "Epoch 296/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8397 - val_loss: 0.3571 - val_accuracy: 0.8596\n",
      "Epoch 297/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8383 - val_loss: 0.3555 - val_accuracy: 0.8708\n",
      "Epoch 298/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.8397 - val_loss: 0.3551 - val_accuracy: 0.8652\n",
      "Epoch 299/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8397 - val_loss: 0.3572 - val_accuracy: 0.8539\n",
      "Epoch 300/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8368 - val_loss: 0.3552 - val_accuracy: 0.8708\n",
      "Epoch 301/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8397 - val_loss: 0.3569 - val_accuracy: 0.8652\n",
      "Epoch 302/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8397 - val_loss: 0.3558 - val_accuracy: 0.8708\n",
      "Epoch 303/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8340 - val_loss: 0.3602 - val_accuracy: 0.8427\n",
      "Epoch 304/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8368 - val_loss: 0.3585 - val_accuracy: 0.8427\n",
      "Epoch 305/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8509 - val_loss: 0.3554 - val_accuracy: 0.8708\n",
      "Epoch 306/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8397 - val_loss: 0.3552 - val_accuracy: 0.8652\n",
      "Epoch 307/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8383 - val_loss: 0.3615 - val_accuracy: 0.8483\n",
      "Epoch 308/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8397 - val_loss: 0.3595 - val_accuracy: 0.8258\n",
      "Epoch 309/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8368 - val_loss: 0.3580 - val_accuracy: 0.8596\n",
      "Epoch 310/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8383 - val_loss: 0.3595 - val_accuracy: 0.8483\n",
      "Epoch 311/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8383 - val_loss: 0.3553 - val_accuracy: 0.8652\n",
      "Epoch 312/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8383 - val_loss: 0.3571 - val_accuracy: 0.8539\n",
      "Epoch 313/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8298 - val_loss: 0.3568 - val_accuracy: 0.8652\n",
      "Epoch 314/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8383 - val_loss: 0.3581 - val_accuracy: 0.8652\n",
      "Epoch 315/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8368 - val_loss: 0.3579 - val_accuracy: 0.8652\n",
      "Epoch 316/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.8383 - val_loss: 0.3583 - val_accuracy: 0.8596\n",
      "Epoch 317/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8467 - val_loss: 0.3601 - val_accuracy: 0.8427\n",
      "Epoch 318/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8383 - val_loss: 0.3556 - val_accuracy: 0.8483\n",
      "Epoch 319/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8397 - val_loss: 0.3539 - val_accuracy: 0.8708\n",
      "Epoch 320/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8425 - val_loss: 0.3575 - val_accuracy: 0.8539\n",
      "Epoch 321/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8453 - val_loss: 0.3581 - val_accuracy: 0.8596\n",
      "Epoch 322/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8453 - val_loss: 0.3586 - val_accuracy: 0.8652\n",
      "Epoch 323/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8354 - val_loss: 0.3584 - val_accuracy: 0.8539\n",
      "Epoch 324/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8383 - val_loss: 0.3597 - val_accuracy: 0.8596\n",
      "Epoch 325/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8383 - val_loss: 0.3579 - val_accuracy: 0.8652\n",
      "Epoch 326/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8481 - val_loss: 0.3585 - val_accuracy: 0.8483\n",
      "Epoch 327/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8425 - val_loss: 0.3564 - val_accuracy: 0.8596\n",
      "Epoch 328/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8397 - val_loss: 0.3578 - val_accuracy: 0.8539\n",
      "Epoch 329/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8425 - val_loss: 0.3576 - val_accuracy: 0.8652\n",
      "Epoch 330/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8383 - val_loss: 0.3599 - val_accuracy: 0.8708\n",
      "Epoch 331/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8340 - val_loss: 0.3657 - val_accuracy: 0.8315\n",
      "Epoch 332/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8312 - val_loss: 0.3590 - val_accuracy: 0.8596\n",
      "Epoch 333/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8439 - val_loss: 0.3566 - val_accuracy: 0.8708\n",
      "Epoch 334/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8439 - val_loss: 0.3614 - val_accuracy: 0.8483\n",
      "Epoch 335/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8411 - val_loss: 0.3577 - val_accuracy: 0.8652\n",
      "Epoch 336/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8425 - val_loss: 0.3592 - val_accuracy: 0.8652\n",
      "Epoch 337/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8340 - val_loss: 0.3628 - val_accuracy: 0.8483\n",
      "Epoch 338/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8383 - val_loss: 0.3613 - val_accuracy: 0.8596\n",
      "Epoch 339/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8383 - val_loss: 0.3581 - val_accuracy: 0.8652\n",
      "Epoch 340/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8383 - val_loss: 0.3577 - val_accuracy: 0.8652\n",
      "Epoch 341/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8425 - val_loss: 0.3643 - val_accuracy: 0.8652\n",
      "Epoch 342/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8368 - val_loss: 0.3589 - val_accuracy: 0.8596\n",
      "Epoch 343/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8397 - val_loss: 0.3611 - val_accuracy: 0.8483\n",
      "Epoch 344/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8383 - val_loss: 0.3624 - val_accuracy: 0.8539\n",
      "Epoch 345/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8368 - val_loss: 0.3570 - val_accuracy: 0.8596\n",
      "Epoch 346/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8368 - val_loss: 0.3621 - val_accuracy: 0.8596\n",
      "Epoch 347/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8397 - val_loss: 0.3580 - val_accuracy: 0.8652\n",
      "Epoch 348/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8411 - val_loss: 0.3618 - val_accuracy: 0.8483\n",
      "Epoch 349/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8481 - val_loss: 0.3559 - val_accuracy: 0.8596\n",
      "Epoch 350/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8354 - val_loss: 0.3592 - val_accuracy: 0.8652\n",
      "Epoch 351/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8397 - val_loss: 0.3615 - val_accuracy: 0.8483\n",
      "Epoch 352/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8453 - val_loss: 0.3607 - val_accuracy: 0.8596\n",
      "Epoch 353/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8467 - val_loss: 0.3584 - val_accuracy: 0.8483\n",
      "Epoch 354/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8425 - val_loss: 0.3610 - val_accuracy: 0.8539\n",
      "Epoch 355/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8383 - val_loss: 0.3597 - val_accuracy: 0.8652\n",
      "Epoch 356/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8439 - val_loss: 0.3595 - val_accuracy: 0.8596\n",
      "Epoch 357/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8411 - val_loss: 0.3585 - val_accuracy: 0.8483\n",
      "Epoch 358/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8439 - val_loss: 0.3612 - val_accuracy: 0.8483\n",
      "Epoch 359/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8383 - val_loss: 0.3603 - val_accuracy: 0.8652\n",
      "Epoch 360/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8425 - val_loss: 0.3633 - val_accuracy: 0.8483\n",
      "Epoch 361/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8453 - val_loss: 0.3580 - val_accuracy: 0.8652\n",
      "Epoch 362/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8411 - val_loss: 0.3679 - val_accuracy: 0.8483\n",
      "Epoch 363/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8340 - val_loss: 0.3642 - val_accuracy: 0.8315\n",
      "Epoch 364/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8411 - val_loss: 0.3645 - val_accuracy: 0.8427\n",
      "Epoch 365/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8411 - val_loss: 0.3628 - val_accuracy: 0.8483\n",
      "Epoch 366/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8439 - val_loss: 0.3633 - val_accuracy: 0.8596\n",
      "Epoch 367/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8425 - val_loss: 0.3644 - val_accuracy: 0.8427\n",
      "Epoch 368/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8397 - val_loss: 0.3613 - val_accuracy: 0.8652\n",
      "Epoch 369/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8509 - val_loss: 0.3603 - val_accuracy: 0.8427\n",
      "Epoch 370/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8411 - val_loss: 0.3588 - val_accuracy: 0.8596\n",
      "Epoch 371/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8425 - val_loss: 0.3615 - val_accuracy: 0.8483\n",
      "Epoch 372/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8354 - val_loss: 0.3604 - val_accuracy: 0.8596\n",
      "Epoch 373/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8439 - val_loss: 0.3636 - val_accuracy: 0.8427\n",
      "Epoch 374/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8439 - val_loss: 0.3583 - val_accuracy: 0.8539\n",
      "Epoch 375/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8340 - val_loss: 0.3625 - val_accuracy: 0.8596\n",
      "Epoch 376/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8453 - val_loss: 0.3633 - val_accuracy: 0.8539\n",
      "Epoch 377/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8397 - val_loss: 0.3616 - val_accuracy: 0.8539\n",
      "Epoch 378/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8453 - val_loss: 0.3609 - val_accuracy: 0.8539\n",
      "Epoch 379/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8439 - val_loss: 0.3612 - val_accuracy: 0.8596\n",
      "Epoch 380/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8326 - val_loss: 0.3630 - val_accuracy: 0.8596\n",
      "Epoch 381/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8425 - val_loss: 0.3611 - val_accuracy: 0.8652\n",
      "Epoch 382/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8439 - val_loss: 0.3584 - val_accuracy: 0.8539\n",
      "Epoch 383/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8425 - val_loss: 0.3628 - val_accuracy: 0.8539\n",
      "Epoch 384/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8453 - val_loss: 0.3590 - val_accuracy: 0.8652\n",
      "Epoch 385/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8439 - val_loss: 0.3618 - val_accuracy: 0.8427\n",
      "Epoch 386/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8383 - val_loss: 0.3609 - val_accuracy: 0.8652\n",
      "Epoch 387/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8439 - val_loss: 0.3623 - val_accuracy: 0.8539\n",
      "Epoch 388/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8439 - val_loss: 0.3645 - val_accuracy: 0.8652\n",
      "Epoch 389/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8411 - val_loss: 0.3615 - val_accuracy: 0.8539\n",
      "Epoch 390/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8242 - val_loss: 0.3614 - val_accuracy: 0.8596\n",
      "Epoch 391/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8340 - val_loss: 0.3620 - val_accuracy: 0.8539\n",
      "Epoch 392/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8383 - val_loss: 0.3639 - val_accuracy: 0.8539\n",
      "Epoch 393/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8453 - val_loss: 0.3642 - val_accuracy: 0.8315\n",
      "Epoch 394/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8439 - val_loss: 0.3601 - val_accuracy: 0.8652\n",
      "Epoch 395/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8467 - val_loss: 0.3599 - val_accuracy: 0.8596\n",
      "Epoch 396/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8368 - val_loss: 0.3671 - val_accuracy: 0.8427\n",
      "Epoch 397/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8481 - val_loss: 0.3622 - val_accuracy: 0.8427\n",
      "Epoch 398/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8425 - val_loss: 0.3630 - val_accuracy: 0.8652\n",
      "Epoch 399/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8354 - val_loss: 0.3635 - val_accuracy: 0.8483\n",
      "Epoch 400/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8439 - val_loss: 0.3624 - val_accuracy: 0.8652\n",
      "Epoch 401/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8453 - val_loss: 0.3624 - val_accuracy: 0.8539\n",
      "Epoch 402/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8425 - val_loss: 0.3647 - val_accuracy: 0.8427\n",
      "Epoch 403/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8481 - val_loss: 0.3587 - val_accuracy: 0.8539\n",
      "Epoch 404/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8425 - val_loss: 0.3605 - val_accuracy: 0.8539\n",
      "Epoch 405/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8467 - val_loss: 0.3636 - val_accuracy: 0.8652\n",
      "Epoch 406/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8397 - val_loss: 0.3615 - val_accuracy: 0.8652\n",
      "Epoch 407/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8495 - val_loss: 0.3645 - val_accuracy: 0.8427\n",
      "Epoch 408/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8425 - val_loss: 0.3630 - val_accuracy: 0.8652\n",
      "Epoch 409/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8411 - val_loss: 0.3684 - val_accuracy: 0.8427\n",
      "Epoch 410/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8481 - val_loss: 0.3621 - val_accuracy: 0.8652\n",
      "Epoch 411/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8439 - val_loss: 0.3621 - val_accuracy: 0.8596\n",
      "Epoch 412/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8425 - val_loss: 0.3630 - val_accuracy: 0.8539\n",
      "Epoch 413/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8467 - val_loss: 0.3648 - val_accuracy: 0.8427\n",
      "Epoch 414/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8340 - val_loss: 0.3616 - val_accuracy: 0.8483\n",
      "Epoch 415/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8425 - val_loss: 0.3663 - val_accuracy: 0.8427\n",
      "Epoch 416/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8368 - val_loss: 0.3627 - val_accuracy: 0.8539\n",
      "Epoch 417/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8439 - val_loss: 0.3664 - val_accuracy: 0.8539\n",
      "Epoch 418/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8411 - val_loss: 0.3604 - val_accuracy: 0.8652\n",
      "Epoch 419/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8425 - val_loss: 0.3603 - val_accuracy: 0.8652\n",
      "Epoch 420/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8439 - val_loss: 0.3657 - val_accuracy: 0.8371\n",
      "Epoch 421/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8383 - val_loss: 0.3629 - val_accuracy: 0.8539\n",
      "Epoch 422/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8397 - val_loss: 0.3633 - val_accuracy: 0.8652\n",
      "Epoch 423/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8453 - val_loss: 0.3640 - val_accuracy: 0.8427\n",
      "Epoch 424/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8481 - val_loss: 0.3625 - val_accuracy: 0.8708\n",
      "Epoch 425/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8411 - val_loss: 0.3679 - val_accuracy: 0.8427\n",
      "Epoch 426/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8425 - val_loss: 0.3628 - val_accuracy: 0.8539\n",
      "Epoch 427/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8354 - val_loss: 0.3637 - val_accuracy: 0.8539\n",
      "Epoch 428/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8425 - val_loss: 0.3660 - val_accuracy: 0.8539\n",
      "Epoch 429/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8425 - val_loss: 0.3637 - val_accuracy: 0.8652\n",
      "Epoch 430/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8425 - val_loss: 0.3617 - val_accuracy: 0.8427\n",
      "Epoch 431/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8439 - val_loss: 0.3629 - val_accuracy: 0.8539\n",
      "Epoch 432/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8453 - val_loss: 0.3695 - val_accuracy: 0.8483\n",
      "Epoch 433/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8425 - val_loss: 0.3618 - val_accuracy: 0.8652\n",
      "Epoch 434/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8425 - val_loss: 0.3643 - val_accuracy: 0.8539\n",
      "Epoch 435/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8453 - val_loss: 0.3666 - val_accuracy: 0.8427\n",
      "Epoch 436/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8439 - val_loss: 0.3615 - val_accuracy: 0.8539\n",
      "Epoch 437/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8383 - val_loss: 0.3614 - val_accuracy: 0.8652\n",
      "Epoch 438/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8425 - val_loss: 0.3629 - val_accuracy: 0.8539\n",
      "Epoch 439/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8467 - val_loss: 0.3628 - val_accuracy: 0.8652\n",
      "Epoch 440/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8425 - val_loss: 0.3628 - val_accuracy: 0.8427\n",
      "Epoch 441/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8509 - val_loss: 0.3630 - val_accuracy: 0.8596\n",
      "Epoch 442/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8411 - val_loss: 0.3626 - val_accuracy: 0.8652\n",
      "Epoch 443/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8411 - val_loss: 0.3636 - val_accuracy: 0.8539\n",
      "Epoch 444/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8495 - val_loss: 0.3634 - val_accuracy: 0.8427\n",
      "Epoch 445/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8453 - val_loss: 0.3634 - val_accuracy: 0.8539\n",
      "Epoch 446/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8467 - val_loss: 0.3691 - val_accuracy: 0.8315\n",
      "Epoch 447/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8411 - val_loss: 0.3636 - val_accuracy: 0.8427\n",
      "Epoch 448/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8425 - val_loss: 0.3641 - val_accuracy: 0.8652\n",
      "Epoch 449/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8495 - val_loss: 0.3684 - val_accuracy: 0.8427\n",
      "Epoch 450/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8439 - val_loss: 0.3648 - val_accuracy: 0.8708\n",
      "Epoch 451/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8467 - val_loss: 0.3648 - val_accuracy: 0.8427\n",
      "Epoch 452/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8411 - val_loss: 0.3655 - val_accuracy: 0.8539\n",
      "Epoch 453/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8411 - val_loss: 0.3650 - val_accuracy: 0.8539\n",
      "Epoch 454/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8495 - val_loss: 0.3623 - val_accuracy: 0.8652\n",
      "Epoch 455/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8383 - val_loss: 0.3702 - val_accuracy: 0.8427\n",
      "Epoch 456/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8411 - val_loss: 0.3651 - val_accuracy: 0.8596\n",
      "Epoch 457/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8411 - val_loss: 0.3646 - val_accuracy: 0.8596\n",
      "Epoch 458/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.8397 - val_loss: 0.3658 - val_accuracy: 0.8315\n",
      "Epoch 459/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8397 - val_loss: 0.3667 - val_accuracy: 0.8596\n",
      "Epoch 460/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8326 - val_loss: 0.3625 - val_accuracy: 0.8539\n",
      "Epoch 461/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8397 - val_loss: 0.3655 - val_accuracy: 0.8427\n",
      "Epoch 462/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8397 - val_loss: 0.3677 - val_accuracy: 0.8315\n",
      "Epoch 463/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8425 - val_loss: 0.3628 - val_accuracy: 0.8652\n",
      "Epoch 464/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8439 - val_loss: 0.3678 - val_accuracy: 0.8315\n",
      "Epoch 465/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8425 - val_loss: 0.3641 - val_accuracy: 0.8596\n",
      "Epoch 466/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8397 - val_loss: 0.3648 - val_accuracy: 0.8427\n",
      "Epoch 467/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8439 - val_loss: 0.3665 - val_accuracy: 0.8539\n",
      "Epoch 468/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8439 - val_loss: 0.3655 - val_accuracy: 0.8539\n",
      "Epoch 469/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8453 - val_loss: 0.3628 - val_accuracy: 0.8539\n",
      "Epoch 470/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8453 - val_loss: 0.3636 - val_accuracy: 0.8652\n",
      "Epoch 471/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8481 - val_loss: 0.3642 - val_accuracy: 0.8427\n",
      "Epoch 472/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8383 - val_loss: 0.3633 - val_accuracy: 0.8652\n",
      "Epoch 473/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8397 - val_loss: 0.3631 - val_accuracy: 0.8427\n",
      "Epoch 474/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8523 - val_loss: 0.3662 - val_accuracy: 0.8483\n",
      "Epoch 475/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8467 - val_loss: 0.3699 - val_accuracy: 0.8315\n",
      "Epoch 476/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8411 - val_loss: 0.3648 - val_accuracy: 0.8652\n",
      "Epoch 477/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8425 - val_loss: 0.3655 - val_accuracy: 0.8483\n",
      "Epoch 478/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8453 - val_loss: 0.3654 - val_accuracy: 0.8539\n",
      "Epoch 479/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8425 - val_loss: 0.3626 - val_accuracy: 0.8483\n",
      "Epoch 480/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8439 - val_loss: 0.3642 - val_accuracy: 0.8483\n",
      "Epoch 481/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8467 - val_loss: 0.3647 - val_accuracy: 0.8596\n",
      "Epoch 482/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8383 - val_loss: 0.3722 - val_accuracy: 0.8371\n",
      "Epoch 483/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8397 - val_loss: 0.3664 - val_accuracy: 0.8652\n",
      "Epoch 484/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8326 - val_loss: 0.3660 - val_accuracy: 0.8483\n",
      "Epoch 485/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8397 - val_loss: 0.3640 - val_accuracy: 0.8596\n",
      "Epoch 486/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8439 - val_loss: 0.3681 - val_accuracy: 0.8539\n",
      "Epoch 487/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8481 - val_loss: 0.3658 - val_accuracy: 0.8539\n",
      "Epoch 488/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8467 - val_loss: 0.3667 - val_accuracy: 0.8427\n",
      "Epoch 489/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8425 - val_loss: 0.3668 - val_accuracy: 0.8539\n",
      "Epoch 490/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8425 - val_loss: 0.3679 - val_accuracy: 0.8427\n",
      "Epoch 491/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8467 - val_loss: 0.3750 - val_accuracy: 0.8483\n",
      "Epoch 492/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8383 - val_loss: 0.3687 - val_accuracy: 0.8427\n",
      "Epoch 493/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8425 - val_loss: 0.3651 - val_accuracy: 0.8539\n",
      "Epoch 494/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8383 - val_loss: 0.3706 - val_accuracy: 0.8427\n",
      "Epoch 495/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8340 - val_loss: 0.3699 - val_accuracy: 0.8652\n",
      "Epoch 496/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8439 - val_loss: 0.3706 - val_accuracy: 0.8315\n",
      "Epoch 497/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8439 - val_loss: 0.3674 - val_accuracy: 0.8539\n",
      "Epoch 498/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8411 - val_loss: 0.3648 - val_accuracy: 0.8652\n",
      "Epoch 499/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8467 - val_loss: 0.3696 - val_accuracy: 0.8371\n",
      "Epoch 500/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8425 - val_loss: 0.3669 - val_accuracy: 0.8539\n",
      "Epoch 501/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8467 - val_loss: 0.3682 - val_accuracy: 0.8483\n",
      "Epoch 502/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8383 - val_loss: 0.3629 - val_accuracy: 0.8596\n",
      "Epoch 503/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8453 - val_loss: 0.3642 - val_accuracy: 0.8427\n",
      "Epoch 504/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8467 - val_loss: 0.3665 - val_accuracy: 0.8652\n",
      "Epoch 505/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8439 - val_loss: 0.3683 - val_accuracy: 0.8315\n",
      "Epoch 506/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8411 - val_loss: 0.3674 - val_accuracy: 0.8483\n",
      "Epoch 507/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8439 - val_loss: 0.3694 - val_accuracy: 0.8596\n",
      "Epoch 508/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8383 - val_loss: 0.3711 - val_accuracy: 0.8539\n",
      "Epoch 509/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8425 - val_loss: 0.3702 - val_accuracy: 0.8596\n",
      "Epoch 510/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8439 - val_loss: 0.3698 - val_accuracy: 0.8596\n",
      "Epoch 511/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8425 - val_loss: 0.3684 - val_accuracy: 0.8539\n",
      "Epoch 512/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8368 - val_loss: 0.3668 - val_accuracy: 0.8427\n",
      "Epoch 513/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8467 - val_loss: 0.3676 - val_accuracy: 0.8652\n",
      "Epoch 514/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8425 - val_loss: 0.3661 - val_accuracy: 0.8483\n",
      "Epoch 515/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8397 - val_loss: 0.3657 - val_accuracy: 0.8596\n",
      "Epoch 516/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8425 - val_loss: 0.3675 - val_accuracy: 0.8427\n",
      "Epoch 517/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8354 - val_loss: 0.3689 - val_accuracy: 0.8539\n",
      "Epoch 518/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8354 - val_loss: 0.3682 - val_accuracy: 0.8315\n",
      "Epoch 519/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8383 - val_loss: 0.3668 - val_accuracy: 0.8708\n",
      "Epoch 520/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8481 - val_loss: 0.3686 - val_accuracy: 0.8315\n",
      "Epoch 521/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8411 - val_loss: 0.3658 - val_accuracy: 0.8596\n",
      "Epoch 522/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8354 - val_loss: 0.3696 - val_accuracy: 0.8427\n",
      "Epoch 523/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8368 - val_loss: 0.3756 - val_accuracy: 0.8483\n",
      "Epoch 524/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8439 - val_loss: 0.3684 - val_accuracy: 0.8427\n",
      "Epoch 525/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8383 - val_loss: 0.3657 - val_accuracy: 0.8427\n",
      "Epoch 526/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8411 - val_loss: 0.3646 - val_accuracy: 0.8596\n",
      "Epoch 527/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8467 - val_loss: 0.3663 - val_accuracy: 0.8652\n",
      "Epoch 528/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8425 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
      "Epoch 529/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8439 - val_loss: 0.3687 - val_accuracy: 0.8539\n",
      "Epoch 530/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8383 - val_loss: 0.3706 - val_accuracy: 0.8539\n",
      "Epoch 531/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8340 - val_loss: 0.3675 - val_accuracy: 0.8652\n",
      "Epoch 532/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8397 - val_loss: 0.3698 - val_accuracy: 0.8427\n",
      "Epoch 533/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8509 - val_loss: 0.3672 - val_accuracy: 0.8539\n",
      "Epoch 534/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8467 - val_loss: 0.3670 - val_accuracy: 0.8539\n",
      "Epoch 535/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8495 - val_loss: 0.3678 - val_accuracy: 0.8427\n",
      "Epoch 536/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8397 - val_loss: 0.3696 - val_accuracy: 0.8483\n",
      "Epoch 537/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8368 - val_loss: 0.3700 - val_accuracy: 0.8427\n",
      "Epoch 538/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8368 - val_loss: 0.3672 - val_accuracy: 0.8539\n",
      "Epoch 539/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8397 - val_loss: 0.3682 - val_accuracy: 0.8539\n",
      "Epoch 540/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8397 - val_loss: 0.3705 - val_accuracy: 0.8539\n",
      "Epoch 541/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.3692 - val_accuracy: 0.8539\n",
      "Epoch 542/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8467 - val_loss: 0.3682 - val_accuracy: 0.8539\n",
      "Epoch 543/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8425 - val_loss: 0.3658 - val_accuracy: 0.8596\n",
      "Epoch 544/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8425 - val_loss: 0.3675 - val_accuracy: 0.8427\n",
      "Epoch 545/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8439 - val_loss: 0.3671 - val_accuracy: 0.8539\n",
      "Epoch 546/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8397 - val_loss: 0.3672 - val_accuracy: 0.8652\n",
      "Epoch 547/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8509 - val_loss: 0.3667 - val_accuracy: 0.8539\n",
      "Epoch 548/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8397 - val_loss: 0.3668 - val_accuracy: 0.8596\n",
      "Epoch 549/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8397 - val_loss: 0.3698 - val_accuracy: 0.8315\n",
      "Epoch 550/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8425 - val_loss: 0.3681 - val_accuracy: 0.8539\n",
      "Epoch 551/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8354 - val_loss: 0.3768 - val_accuracy: 0.8315\n",
      "Epoch 552/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8509 - val_loss: 0.3691 - val_accuracy: 0.8483\n",
      "Epoch 553/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8397 - val_loss: 0.3686 - val_accuracy: 0.8596\n",
      "Epoch 554/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8383 - val_loss: 0.3690 - val_accuracy: 0.8539\n",
      "Epoch 555/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8481 - val_loss: 0.3680 - val_accuracy: 0.8483\n",
      "Epoch 556/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.3781 - val_accuracy: 0.8315\n",
      "Epoch 557/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8467 - val_loss: 0.3702 - val_accuracy: 0.8596\n",
      "Epoch 558/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8495 - val_loss: 0.3696 - val_accuracy: 0.8427\n",
      "Epoch 559/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8397 - val_loss: 0.3675 - val_accuracy: 0.8539\n",
      "Epoch 560/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8495 - val_loss: 0.3722 - val_accuracy: 0.8315\n",
      "Epoch 561/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8495 - val_loss: 0.3702 - val_accuracy: 0.8539\n",
      "Epoch 562/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8453 - val_loss: 0.3687 - val_accuracy: 0.8427\n",
      "Epoch 563/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8439 - val_loss: 0.3712 - val_accuracy: 0.8315\n",
      "Epoch 564/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8397 - val_loss: 0.3673 - val_accuracy: 0.8539\n",
      "Epoch 565/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8453 - val_loss: 0.3688 - val_accuracy: 0.8427\n",
      "Epoch 566/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8453 - val_loss: 0.3692 - val_accuracy: 0.8427\n",
      "Epoch 567/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8397 - val_loss: 0.3684 - val_accuracy: 0.8483\n",
      "Epoch 568/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8467 - val_loss: 0.3686 - val_accuracy: 0.8596\n",
      "Epoch 569/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8481 - val_loss: 0.3694 - val_accuracy: 0.8483\n",
      "Epoch 570/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8509 - val_loss: 0.3708 - val_accuracy: 0.8539\n",
      "Epoch 571/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8383 - val_loss: 0.3684 - val_accuracy: 0.8315\n",
      "Epoch 572/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8340 - val_loss: 0.3681 - val_accuracy: 0.8483\n",
      "Epoch 573/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8411 - val_loss: 0.3751 - val_accuracy: 0.8539\n",
      "Epoch 574/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8481 - val_loss: 0.3733 - val_accuracy: 0.8483\n",
      "Epoch 575/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8565 - val_loss: 0.3697 - val_accuracy: 0.8427\n",
      "Epoch 576/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8425 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
      "Epoch 577/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8397 - val_loss: 0.3665 - val_accuracy: 0.8483\n",
      "Epoch 578/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8453 - val_loss: 0.3652 - val_accuracy: 0.8539\n",
      "Epoch 579/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8397 - val_loss: 0.3697 - val_accuracy: 0.8539\n",
      "Epoch 580/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8495 - val_loss: 0.3703 - val_accuracy: 0.8483\n",
      "Epoch 581/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8411 - val_loss: 0.3694 - val_accuracy: 0.8539\n",
      "Epoch 582/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8411 - val_loss: 0.3729 - val_accuracy: 0.8315\n",
      "Epoch 583/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8453 - val_loss: 0.3679 - val_accuracy: 0.8539\n",
      "Epoch 584/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.8453 - val_loss: 0.3677 - val_accuracy: 0.8427\n",
      "Epoch 585/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8467 - val_loss: 0.3660 - val_accuracy: 0.8652\n",
      "Epoch 586/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8453 - val_loss: 0.3704 - val_accuracy: 0.8539\n",
      "Epoch 587/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8453 - val_loss: 0.3695 - val_accuracy: 0.8427\n",
      "Epoch 588/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8453 - val_loss: 0.3694 - val_accuracy: 0.8371\n",
      "Epoch 589/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8495 - val_loss: 0.3741 - val_accuracy: 0.8427\n",
      "Epoch 590/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8523 - val_loss: 0.3699 - val_accuracy: 0.8539\n",
      "Epoch 591/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8495 - val_loss: 0.3695 - val_accuracy: 0.8371\n",
      "Epoch 592/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8439 - val_loss: 0.3711 - val_accuracy: 0.8483\n",
      "Epoch 593/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8425 - val_loss: 0.3699 - val_accuracy: 0.8596\n",
      "Epoch 594/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8467 - val_loss: 0.3685 - val_accuracy: 0.8427\n",
      "Epoch 595/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8481 - val_loss: 0.3765 - val_accuracy: 0.8427\n",
      "Epoch 596/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8368 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
      "Epoch 597/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8326 - val_loss: 0.3719 - val_accuracy: 0.8539\n",
      "Epoch 598/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8397 - val_loss: 0.3708 - val_accuracy: 0.8427\n",
      "Epoch 599/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8453 - val_loss: 0.3700 - val_accuracy: 0.8427\n",
      "Epoch 600/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8439 - val_loss: 0.3698 - val_accuracy: 0.8427\n",
      "Epoch 601/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8439 - val_loss: 0.3678 - val_accuracy: 0.8539\n",
      "Epoch 602/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8467 - val_loss: 0.3740 - val_accuracy: 0.8539\n",
      "Epoch 603/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8495 - val_loss: 0.3700 - val_accuracy: 0.8371\n",
      "Epoch 604/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8453 - val_loss: 0.3722 - val_accuracy: 0.8539\n",
      "Epoch 605/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8467 - val_loss: 0.3718 - val_accuracy: 0.8427\n",
      "Epoch 606/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8453 - val_loss: 0.3703 - val_accuracy: 0.8539\n",
      "Epoch 607/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8411 - val_loss: 0.3741 - val_accuracy: 0.8427\n",
      "Epoch 608/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8439 - val_loss: 0.3684 - val_accuracy: 0.8539\n",
      "Epoch 609/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8453 - val_loss: 0.3707 - val_accuracy: 0.8483\n",
      "Epoch 610/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8481 - val_loss: 0.3738 - val_accuracy: 0.8483\n",
      "Epoch 611/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8439 - val_loss: 0.3710 - val_accuracy: 0.8483\n",
      "Epoch 612/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8481 - val_loss: 0.3723 - val_accuracy: 0.8483\n",
      "Epoch 613/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8439 - val_loss: 0.3701 - val_accuracy: 0.8539\n",
      "Epoch 614/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8411 - val_loss: 0.3726 - val_accuracy: 0.8427\n",
      "Epoch 615/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8439 - val_loss: 0.3770 - val_accuracy: 0.8315\n",
      "Epoch 616/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8411 - val_loss: 0.3726 - val_accuracy: 0.8258\n",
      "Epoch 617/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8439 - val_loss: 0.3763 - val_accuracy: 0.8315\n",
      "Epoch 618/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8411 - val_loss: 0.3724 - val_accuracy: 0.8483\n",
      "Epoch 619/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8467 - val_loss: 0.3728 - val_accuracy: 0.8427\n",
      "Epoch 620/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8425 - val_loss: 0.3729 - val_accuracy: 0.8427\n",
      "Epoch 621/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8439 - val_loss: 0.3765 - val_accuracy: 0.8315\n",
      "Epoch 622/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8411 - val_loss: 0.3710 - val_accuracy: 0.8427\n",
      "Epoch 623/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8354 - val_loss: 0.3758 - val_accuracy: 0.8371\n",
      "Epoch 624/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8439 - val_loss: 0.3719 - val_accuracy: 0.8596\n",
      "Epoch 625/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8411 - val_loss: 0.3756 - val_accuracy: 0.8371\n",
      "Epoch 626/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8368 - val_loss: 0.3726 - val_accuracy: 0.8539\n",
      "Epoch 627/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8397 - val_loss: 0.3702 - val_accuracy: 0.8427\n",
      "Epoch 628/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8383 - val_loss: 0.3738 - val_accuracy: 0.8539\n",
      "Epoch 629/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8439 - val_loss: 0.3728 - val_accuracy: 0.8539\n",
      "Epoch 630/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8383 - val_loss: 0.3756 - val_accuracy: 0.8596\n",
      "Epoch 631/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8411 - val_loss: 0.3897 - val_accuracy: 0.8202\n",
      "Epoch 632/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8383 - val_loss: 0.3713 - val_accuracy: 0.8539\n",
      "Epoch 633/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8368 - val_loss: 0.3726 - val_accuracy: 0.8315\n",
      "Epoch 634/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8397 - val_loss: 0.3695 - val_accuracy: 0.8539\n",
      "Epoch 635/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8439 - val_loss: 0.3729 - val_accuracy: 0.8315\n",
      "Epoch 636/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8495 - val_loss: 0.3711 - val_accuracy: 0.8596\n",
      "Epoch 637/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8383 - val_loss: 0.3720 - val_accuracy: 0.8483\n",
      "Epoch 638/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8397 - val_loss: 0.3702 - val_accuracy: 0.8596\n",
      "Epoch 639/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8354 - val_loss: 0.3708 - val_accuracy: 0.8483\n",
      "Epoch 640/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8495 - val_loss: 0.3753 - val_accuracy: 0.8371\n",
      "Epoch 641/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8453 - val_loss: 0.3716 - val_accuracy: 0.8539\n",
      "Epoch 642/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8425 - val_loss: 0.3710 - val_accuracy: 0.8427\n",
      "Epoch 643/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8411 - val_loss: 0.3716 - val_accuracy: 0.8315\n",
      "Epoch 644/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8397 - val_loss: 0.3696 - val_accuracy: 0.8596\n",
      "Epoch 645/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8453 - val_loss: 0.3708 - val_accuracy: 0.8427\n",
      "Epoch 646/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8453 - val_loss: 0.3716 - val_accuracy: 0.8427\n",
      "Epoch 647/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8537 - val_loss: 0.3710 - val_accuracy: 0.8596\n",
      "Epoch 648/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8425 - val_loss: 0.3720 - val_accuracy: 0.8539\n",
      "Epoch 649/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8523 - val_loss: 0.3703 - val_accuracy: 0.8539\n",
      "Epoch 650/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8481 - val_loss: 0.3750 - val_accuracy: 0.8371\n",
      "Epoch 651/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8354 - val_loss: 0.3739 - val_accuracy: 0.8315\n",
      "Epoch 652/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8425 - val_loss: 0.3711 - val_accuracy: 0.8427\n",
      "Epoch 653/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8425 - val_loss: 0.3699 - val_accuracy: 0.8596\n",
      "Epoch 654/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8439 - val_loss: 0.3700 - val_accuracy: 0.8539\n",
      "Epoch 655/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8453 - val_loss: 0.3714 - val_accuracy: 0.8596\n",
      "Epoch 656/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8368 - val_loss: 0.3733 - val_accuracy: 0.8596\n",
      "Epoch 657/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8509 - val_loss: 0.3717 - val_accuracy: 0.8483\n",
      "Epoch 658/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8411 - val_loss: 0.3699 - val_accuracy: 0.8596\n",
      "Epoch 659/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8368 - val_loss: 0.3713 - val_accuracy: 0.8596\n",
      "Epoch 660/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8425 - val_loss: 0.3731 - val_accuracy: 0.8483\n",
      "Epoch 661/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8425 - val_loss: 0.3710 - val_accuracy: 0.8539\n",
      "Epoch 662/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8383 - val_loss: 0.3721 - val_accuracy: 0.8596\n",
      "Epoch 663/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8453 - val_loss: 0.3725 - val_accuracy: 0.8315\n",
      "Epoch 664/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8439 - val_loss: 0.3740 - val_accuracy: 0.8483\n",
      "Epoch 665/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8467 - val_loss: 0.3717 - val_accuracy: 0.8315\n",
      "Epoch 666/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8425 - val_loss: 0.3746 - val_accuracy: 0.8483\n",
      "Epoch 667/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8411 - val_loss: 0.3721 - val_accuracy: 0.8427\n",
      "Epoch 668/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8425 - val_loss: 0.3718 - val_accuracy: 0.8427\n",
      "Epoch 669/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8425 - val_loss: 0.3725 - val_accuracy: 0.8427\n",
      "Epoch 670/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8425 - val_loss: 0.3728 - val_accuracy: 0.8371\n",
      "Epoch 671/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8411 - val_loss: 0.3701 - val_accuracy: 0.8427\n",
      "Epoch 672/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8467 - val_loss: 0.3698 - val_accuracy: 0.8539\n",
      "Epoch 673/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8453 - val_loss: 0.3692 - val_accuracy: 0.8539\n",
      "Epoch 674/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8467 - val_loss: 0.3717 - val_accuracy: 0.8371\n",
      "Epoch 675/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8439 - val_loss: 0.3784 - val_accuracy: 0.8315\n",
      "Epoch 676/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8439 - val_loss: 0.3712 - val_accuracy: 0.8539\n",
      "Epoch 677/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8439 - val_loss: 0.3720 - val_accuracy: 0.8483\n",
      "Epoch 678/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8481 - val_loss: 0.3721 - val_accuracy: 0.8596\n",
      "Epoch 679/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8397 - val_loss: 0.3699 - val_accuracy: 0.8596\n",
      "Epoch 680/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8495 - val_loss: 0.3733 - val_accuracy: 0.8427\n",
      "Epoch 681/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8411 - val_loss: 0.3735 - val_accuracy: 0.8315\n",
      "Epoch 682/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8495 - val_loss: 0.3731 - val_accuracy: 0.8371\n",
      "Epoch 683/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8439 - val_loss: 0.3707 - val_accuracy: 0.8596\n",
      "Epoch 684/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8453 - val_loss: 0.3707 - val_accuracy: 0.8483\n",
      "Epoch 685/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8467 - val_loss: 0.3719 - val_accuracy: 0.8427\n",
      "Epoch 686/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8411 - val_loss: 0.3735 - val_accuracy: 0.8539\n",
      "Epoch 687/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8383 - val_loss: 0.3763 - val_accuracy: 0.8315\n",
      "Epoch 688/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8439 - val_loss: 0.3750 - val_accuracy: 0.8483\n",
      "Epoch 689/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8453 - val_loss: 0.3722 - val_accuracy: 0.8483\n",
      "Epoch 690/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8495 - val_loss: 0.3720 - val_accuracy: 0.8483\n",
      "Epoch 691/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8383 - val_loss: 0.3708 - val_accuracy: 0.8483\n",
      "Epoch 692/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8453 - val_loss: 0.3718 - val_accuracy: 0.8483\n",
      "Epoch 693/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8467 - val_loss: 0.3719 - val_accuracy: 0.8596\n",
      "Epoch 694/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8425 - val_loss: 0.3738 - val_accuracy: 0.8596\n",
      "Epoch 695/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8411 - val_loss: 0.3732 - val_accuracy: 0.8315\n",
      "Epoch 696/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8481 - val_loss: 0.3706 - val_accuracy: 0.8539\n",
      "Epoch 697/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8354 - val_loss: 0.3751 - val_accuracy: 0.8371\n",
      "Epoch 698/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8467 - val_loss: 0.3744 - val_accuracy: 0.8483\n",
      "Epoch 699/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8439 - val_loss: 0.3719 - val_accuracy: 0.8427\n",
      "Epoch 700/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8495 - val_loss: 0.3736 - val_accuracy: 0.8596\n",
      "Epoch 701/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8467 - val_loss: 0.3750 - val_accuracy: 0.8371\n",
      "Epoch 702/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8439 - val_loss: 0.3731 - val_accuracy: 0.8315\n",
      "Epoch 703/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8495 - val_loss: 0.3703 - val_accuracy: 0.8652\n",
      "Epoch 704/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8467 - val_loss: 0.3723 - val_accuracy: 0.8483\n",
      "Epoch 705/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8481 - val_loss: 0.3773 - val_accuracy: 0.8427\n",
      "Epoch 706/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8453 - val_loss: 0.3738 - val_accuracy: 0.8427\n",
      "Epoch 707/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8481 - val_loss: 0.3743 - val_accuracy: 0.8427\n",
      "Epoch 708/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8425 - val_loss: 0.3720 - val_accuracy: 0.8596\n",
      "Epoch 709/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8495 - val_loss: 0.3731 - val_accuracy: 0.8371\n",
      "Epoch 710/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8439 - val_loss: 0.3712 - val_accuracy: 0.8483\n",
      "Epoch 711/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8467 - val_loss: 0.3724 - val_accuracy: 0.8371\n",
      "Epoch 712/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8411 - val_loss: 0.3719 - val_accuracy: 0.8539\n",
      "Epoch 713/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8467 - val_loss: 0.3749 - val_accuracy: 0.8315\n",
      "Epoch 714/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8523 - val_loss: 0.3748 - val_accuracy: 0.8483\n",
      "Epoch 715/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8383 - val_loss: 0.3793 - val_accuracy: 0.8315\n",
      "Epoch 716/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8495 - val_loss: 0.3750 - val_accuracy: 0.8427\n",
      "Epoch 717/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8383 - val_loss: 0.3756 - val_accuracy: 0.8371\n",
      "Epoch 718/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8453 - val_loss: 0.3833 - val_accuracy: 0.8315\n",
      "Epoch 719/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8368 - val_loss: 0.3740 - val_accuracy: 0.8539\n",
      "Epoch 720/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8425 - val_loss: 0.3728 - val_accuracy: 0.8596\n",
      "Epoch 721/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8340 - val_loss: 0.3739 - val_accuracy: 0.8596\n",
      "Epoch 722/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8467 - val_loss: 0.3784 - val_accuracy: 0.8315\n",
      "Epoch 723/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8439 - val_loss: 0.3736 - val_accuracy: 0.8539\n",
      "Epoch 724/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8453 - val_loss: 0.3768 - val_accuracy: 0.8539\n",
      "Epoch 725/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8411 - val_loss: 0.3779 - val_accuracy: 0.8371\n",
      "Epoch 726/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8439 - val_loss: 0.3740 - val_accuracy: 0.8539\n",
      "Epoch 727/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8495 - val_loss: 0.3744 - val_accuracy: 0.8427\n",
      "Epoch 728/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8439 - val_loss: 0.3760 - val_accuracy: 0.8483\n",
      "Epoch 729/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8495 - val_loss: 0.3757 - val_accuracy: 0.8315\n",
      "Epoch 730/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8453 - val_loss: 0.3734 - val_accuracy: 0.8539\n",
      "Epoch 731/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8467 - val_loss: 0.3741 - val_accuracy: 0.8596\n",
      "Epoch 732/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8453 - val_loss: 0.3819 - val_accuracy: 0.8315\n",
      "Epoch 733/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8481 - val_loss: 0.3765 - val_accuracy: 0.8483\n",
      "Epoch 734/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8467 - val_loss: 0.3767 - val_accuracy: 0.8483\n",
      "Epoch 735/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8425 - val_loss: 0.3768 - val_accuracy: 0.8315\n",
      "Epoch 736/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8368 - val_loss: 0.3814 - val_accuracy: 0.8315\n",
      "Epoch 737/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8397 - val_loss: 0.3798 - val_accuracy: 0.8539\n",
      "Epoch 738/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8439 - val_loss: 0.3810 - val_accuracy: 0.8371\n",
      "Epoch 739/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8467 - val_loss: 0.3781 - val_accuracy: 0.8371\n",
      "Epoch 740/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8523 - val_loss: 0.3813 - val_accuracy: 0.8539\n",
      "Epoch 741/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8397 - val_loss: 0.3759 - val_accuracy: 0.8652\n",
      "Epoch 742/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8453 - val_loss: 0.3786 - val_accuracy: 0.8539\n",
      "Epoch 743/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8425 - val_loss: 0.3769 - val_accuracy: 0.8596\n",
      "Epoch 744/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8397 - val_loss: 0.3810 - val_accuracy: 0.8539\n",
      "Epoch 745/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8453 - val_loss: 0.3843 - val_accuracy: 0.8371\n",
      "Epoch 746/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8439 - val_loss: 0.3788 - val_accuracy: 0.8539\n",
      "Epoch 747/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8368 - val_loss: 0.3796 - val_accuracy: 0.8539\n",
      "Epoch 748/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8425 - val_loss: 0.3815 - val_accuracy: 0.8427\n",
      "Epoch 749/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8509 - val_loss: 0.3809 - val_accuracy: 0.8371\n",
      "Epoch 750/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8411 - val_loss: 0.3773 - val_accuracy: 0.8427\n",
      "Epoch 751/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8439 - val_loss: 0.3788 - val_accuracy: 0.8539\n",
      "Epoch 752/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8397 - val_loss: 0.3812 - val_accuracy: 0.8427\n",
      "Epoch 753/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3594 - accuracy: 0.8467 - val_loss: 0.3831 - val_accuracy: 0.8539\n",
      "Epoch 754/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8439 - val_loss: 0.3797 - val_accuracy: 0.8427\n",
      "Epoch 755/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8439 - val_loss: 0.3795 - val_accuracy: 0.8427\n",
      "Epoch 756/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8495 - val_loss: 0.3790 - val_accuracy: 0.8539\n",
      "Epoch 757/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8481 - val_loss: 0.3800 - val_accuracy: 0.8539\n",
      "Epoch 758/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8523 - val_loss: 0.3796 - val_accuracy: 0.8596\n",
      "Epoch 759/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8495 - val_loss: 0.3777 - val_accuracy: 0.8596\n",
      "Epoch 760/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8467 - val_loss: 0.3794 - val_accuracy: 0.8539\n",
      "Epoch 761/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8425 - val_loss: 0.3812 - val_accuracy: 0.8315\n",
      "Epoch 762/800\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8565 - val_loss: 0.3801 - val_accuracy: 0.8596\n",
      "Epoch 763/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8495 - val_loss: 0.3904 - val_accuracy: 0.8258\n",
      "Epoch 764/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8523 - val_loss: 0.3949 - val_accuracy: 0.8371\n",
      "Epoch 765/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8411 - val_loss: 0.4012 - val_accuracy: 0.8315\n",
      "Epoch 766/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8312 - val_loss: 0.3796 - val_accuracy: 0.8539\n",
      "Epoch 767/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8453 - val_loss: 0.3815 - val_accuracy: 0.8539\n",
      "Epoch 768/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8453 - val_loss: 0.3829 - val_accuracy: 0.8427\n",
      "Epoch 769/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8467 - val_loss: 0.3846 - val_accuracy: 0.8483\n",
      "Epoch 770/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8397 - val_loss: 0.3796 - val_accuracy: 0.8539\n",
      "Epoch 771/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8411 - val_loss: 0.3793 - val_accuracy: 0.8371\n",
      "Epoch 772/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8467 - val_loss: 0.3865 - val_accuracy: 0.8315\n",
      "Epoch 773/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8383 - val_loss: 0.3786 - val_accuracy: 0.8483\n",
      "Epoch 774/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8509 - val_loss: 0.3830 - val_accuracy: 0.8427\n",
      "Epoch 775/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8523 - val_loss: 0.3798 - val_accuracy: 0.8596\n",
      "Epoch 776/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8425 - val_loss: 0.3810 - val_accuracy: 0.8371\n",
      "Epoch 777/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3626 - accuracy: 0.8509 - val_loss: 0.3812 - val_accuracy: 0.8427\n",
      "Epoch 778/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8481 - val_loss: 0.3813 - val_accuracy: 0.8483\n",
      "Epoch 779/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3597 - accuracy: 0.8495 - val_loss: 0.3800 - val_accuracy: 0.8483\n",
      "Epoch 780/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8481 - val_loss: 0.3793 - val_accuracy: 0.8483\n",
      "Epoch 781/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8495 - val_loss: 0.3787 - val_accuracy: 0.8652\n",
      "Epoch 782/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8453 - val_loss: 0.3833 - val_accuracy: 0.8596\n",
      "Epoch 783/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3577 - accuracy: 0.8481 - val_loss: 0.3806 - val_accuracy: 0.8539\n",
      "Epoch 784/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8467 - val_loss: 0.3877 - val_accuracy: 0.8371\n",
      "Epoch 785/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8523 - val_loss: 0.3791 - val_accuracy: 0.8371\n",
      "Epoch 786/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8509 - val_loss: 0.3802 - val_accuracy: 0.8596\n",
      "Epoch 787/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3594 - accuracy: 0.8509 - val_loss: 0.3808 - val_accuracy: 0.8596\n",
      "Epoch 788/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8453 - val_loss: 0.3805 - val_accuracy: 0.8371\n",
      "Epoch 789/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8439 - val_loss: 0.3812 - val_accuracy: 0.8427\n",
      "Epoch 790/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8467 - val_loss: 0.3884 - val_accuracy: 0.8315\n",
      "Epoch 791/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8453 - val_loss: 0.3852 - val_accuracy: 0.8315\n",
      "Epoch 792/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8551 - val_loss: 0.3867 - val_accuracy: 0.8483\n",
      "Epoch 793/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.8411 - val_loss: 0.3815 - val_accuracy: 0.8427\n",
      "Epoch 794/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8383 - val_loss: 0.3824 - val_accuracy: 0.8539\n",
      "Epoch 795/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8565 - val_loss: 0.3874 - val_accuracy: 0.8315\n",
      "Epoch 796/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8509 - val_loss: 0.3790 - val_accuracy: 0.8539\n",
      "Epoch 797/800\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8523 - val_loss: 0.3914 - val_accuracy: 0.8483\n",
      "Epoch 798/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8397 - val_loss: 0.3830 - val_accuracy: 0.8483\n",
      "Epoch 799/800\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.8439 - val_loss: 0.3824 - val_accuracy: 0.8315\n",
      "Epoch 800/800\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8397 - val_loss: 0.3794 - val_accuracy: 0.8427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ce9db9b160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictions of test data\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "y_final = (prediction >= 0.5).astype(int).reshape(X_test.shape[0])\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_final})\n",
    "output.to_csv('prediction.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
