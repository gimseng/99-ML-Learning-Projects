The jupyter notebook file "Cartpole_Player.ipynb" consists of code and explaination of 3 playing policies :- 

1. Random playing strategy
2. Playing multiple episodes with varying initial environment and weights and storing the best weights.
3. Deep Q-learner strategy where we use neural network to store the optimum weights after periodically decreasing the exploration exploitation ratio.

The folder "cartpole_model" consists of the output weights after each 50 episodes.

