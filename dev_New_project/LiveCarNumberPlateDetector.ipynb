{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05NB1786\n",
      "KA95NB1786\n",
      "KA95N81786\n",
      "KA05NB1786\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "## -----------   Load Pre-trained Models ------------\n",
    "model = cv2.dnn.readNet('frozen_east_text_detection.pb')\n",
    "model1 = cv2.dnn.readNet('crnn.onnx')\n",
    "\n",
    "def most_likely(scores, char_set):\n",
    "    text = \"\"\n",
    "    for i in range(scores.shape[0]):\n",
    "        c = np.argmax(scores[i][0])\n",
    "        text += char_set[c]\n",
    "    return text\n",
    "\n",
    "def map_rule(text):\n",
    "    char_list = []\n",
    "    for i in range(len(text)):\n",
    "        if i == 0:\n",
    "            if text[i] != '-':\n",
    "                char_list.append(text[i])\n",
    "        else:\n",
    "            if text[i] != '-' and (not (text[i] == text[i - 1])):\n",
    "                char_list.append(text[i])\n",
    "    return ''.join(char_list)\n",
    "\n",
    "def best_path(scores, char_set):\n",
    "    text = most_likely(scores, char_set)\n",
    "    final_text = map_rule(text)\n",
    "    return final_text\n",
    "\n",
    "alphabet_set = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "blank = '-'\n",
    "\n",
    "char_set = blank + alphabet_set\n",
    "\n",
    "def mainfn():\n",
    "    #img = cv2.imread(\"kia-seltos-car-number-plate-designs.jpeg\")\n",
    "    img = cv2.imread(\"pic.jpg\")\n",
    "    # use multiple of 32 to set the new img shape\n",
    "    height, width, _ = img.shape\n",
    "    new_height = (height//32)*32\n",
    "    new_width = (width//32)*32\n",
    "\n",
    "    # get the ratio change in width and height\n",
    "    h_ratio = height/new_height\n",
    "    w_ratio = width/new_width\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img,1.0, (new_width, new_height), (123.68, 116.78, 103.94), True, False)\n",
    "\n",
    "    model.setInput(blob)\n",
    "    (geometry, scores) = model.forward(model.getUnconnectedOutLayersNames())\n",
    "\n",
    "    rectangles = []\n",
    "    confidence_score = []\n",
    "    for i in range(geometry.shape[2]):\n",
    "            for j in range(0, geometry.shape[3]):\n",
    "\n",
    "                if scores[0][0][i][j] < 0.1:\n",
    "                    continue\n",
    "\n",
    "                bottom_x = int(j*4 + geometry[0][1][i][j])\n",
    "                bottom_y = int(i*4 + geometry[0][2][i][j])\n",
    "\n",
    "\n",
    "                top_x = int(j*4 - geometry[0][3][i][j])\n",
    "                top_y = int(i*4 - geometry[0][0][i][j])\n",
    "\n",
    "                rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "                confidence_score.append(float(scores[0][0][i][j]))\n",
    "\n",
    "    # use Non-max suppression to get the required rectangles\n",
    "    fin_boxes = non_max_suppression(np.array(rectangles), probs=confidence_score, overlapThresh=0.5)\n",
    "\n",
    "    img_copy = img.copy()\n",
    "    chara = {}\n",
    "    for (x1, y1, x2, y2) in fin_boxes:\n",
    "\n",
    "        x1 = int(x1 * w_ratio)\n",
    "        y1 = int(y1 * h_ratio)\n",
    "        x2 = int(x2 * w_ratio)\n",
    "        y2 = int(y2 * h_ratio)\n",
    "       \n",
    "        segment = img[y1:y2, x1:x2, :]\n",
    "        #segment = img[y1:y2, x1:x2, :]\n",
    "        segment_gray = cv2.cvtColor(segment, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(segment_gray, scalefactor=1/127.5, size=(100,32), mean=127.5)\n",
    "        model1.setInput(blob)\n",
    "        scores = model1.forward()\n",
    "        text = best_path(scores, char_set)\n",
    "        chara[x1] = text\n",
    "        #print(text)\n",
    "        \n",
    "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img_copy, text.strip(), (x1,y1-2), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255),2)\n",
    "\n",
    "    final=[]\n",
    "    for j in sorted(chara):\n",
    "        final.append(chara[j])\n",
    "    #print(final)\n",
    "    s = \"\"\n",
    "    s = s.join(final)\n",
    "    return s\n",
    "\n",
    "## ----------  Performing OCR in live video ----------\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count=0\n",
    "while cap.isOpened():\n",
    "    \n",
    "    count=count+1\n",
    "    ret, img = cap.read()\n",
    "    if count == 10:\n",
    "        cv2.imwrite(\"pic.jpg\", img)\n",
    "        #print(\"pic clicked\")\n",
    "        output_val = mainfn()\n",
    "        print(output_val) \n",
    "        #break\n",
    "        count=0\n",
    "    # use multiple of 32 to set the new img shape\n",
    "    height, width, _ = img.shape\n",
    "    new_height = (height//32)*32\n",
    "    new_width = (width//32)*32\n",
    "\n",
    "    # get the ratio change in width and height\n",
    "    h_ratio = height/new_height\n",
    "    w_ratio = width/new_width\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img,1.0, (new_width, new_height), (123.68, 116.78, 103.94), True, False)\n",
    "\n",
    "    model.setInput(blob)\n",
    "    (geometry, scores) = model.forward(model.getUnconnectedOutLayersNames())\n",
    "\n",
    "    rectangles = []\n",
    "    confidence_score = []\n",
    "    for i in range(geometry.shape[2]):\n",
    "        for j in range(0, geometry.shape[3]):\n",
    "\n",
    "            if scores[0][0][i][j] < 0.1:\n",
    "                continue\n",
    "\n",
    "            bottom_x = int(j*4 + geometry[0][1][i][j])\n",
    "            bottom_y = int(i*4 + geometry[0][2][i][j])\n",
    "\n",
    "\n",
    "            top_x = int(j*4 - geometry[0][3][i][j])\n",
    "            top_y = int(i*4 - geometry[0][0][i][j])\n",
    "\n",
    "            rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "            confidence_score.append(float(scores[0][0][i][j]))\n",
    "\n",
    "    # use Non-max suppression to get the required rectangles\n",
    "    fin_boxes = non_max_suppression(np.array(rectangles), probs=confidence_score, overlapThresh=0.5)\n",
    "\n",
    "    img_copy = img.copy()\n",
    "    for (x1, y1, x2, y2) in fin_boxes:\n",
    "\n",
    "        x1 = int(x1 * w_ratio)\n",
    "        y1 = int(y1 * h_ratio)\n",
    "        x2 = int(x2 * w_ratio)\n",
    "        y2 = int(y2 * h_ratio)\n",
    "    \n",
    "        #segment = img[y1:y2+4, x1:x2+2, :]\n",
    "        segment = img[y1:y2, x1:x2, :]\n",
    "        segment_gray = cv2.cvtColor(segment, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImage(segment_gray, scalefactor=1/127.5, size=(100,32), mean=127.5)\n",
    "        model1.setInput(blob)\n",
    "        scores = model1.forward()\n",
    "        text = best_path(scores, char_set)\n",
    "        #print(text)\n",
    "\n",
    "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img_copy, text.strip(), (x1,y1-2), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,255),2)\n",
    "\n",
    "    cv2.imshow(\"Text Detection\", img_copy)\n",
    "    if cv2.waitKey(1) == 113:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
